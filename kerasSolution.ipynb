{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Problem set: Tensorflow</h1>\n",
    "1. Loading Iris Dataset into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adapted from: https://github.com/salmanahmad4u/keras-iris/blob/master/iris_nn.py\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import keras as kr\n",
    "\n",
    "# Loading in the Iris dataset\n",
    "iris = list(csv.reader(open('iris.csv')))[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the strings consistently to integers and then convert the vector of integers to a one hot encoding using the Keras function to_categorical()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The inputs are four floats\n",
    "inpts  = np.array(iris)[:,:4].astype(np.float)\n",
    "\n",
    "# Outputs are initially individual strings: setosa, versicolor or virginica.\n",
    "out = np.array(iris)[:,4]\n",
    "# Converting the strings to ints.\n",
    "out_vals, out_ints = np.unique(out, return_inverse=True)\n",
    "# Encode the category integers as binary categorical variables.\n",
    "out_cats = kr.utils.to_categorical(out_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Spliting the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inds = np.random.permutation(len(inpts))\n",
    "train_inds, test_inds = np.array_split(inds, 2)\n",
    "input_train, output_train = inpts[train_inds], out_cats[train_inds]\n",
    "input_test,  output_test  = inpts[test_inds],  out_cats[test_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 1.0858 - acc: 0.3333\n",
      "Epoch 2/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0129 - acc: 0.3333\n",
      "Epoch 3/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.9720 - acc: 0.5467\n",
      "Epoch 4/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.9364 - acc: 0.6800\n",
      "Epoch 5/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.9016 - acc: 0.6667\n",
      "Epoch 6/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.8666 - acc: 0.7467\n",
      "Epoch 7/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.8214 - acc: 0.7600\n",
      "Epoch 8/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.7640 - acc: 0.7733\n",
      "Epoch 9/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.7224 - acc: 0.9733\n",
      "Epoch 10/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6868 - acc: 0.8933\n",
      "Epoch 11/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6599 - acc: 0.7067\n",
      "Epoch 12/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6314 - acc: 0.9333\n",
      "Epoch 13/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6037 - acc: 0.8000\n",
      "Epoch 14/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5837 - acc: 0.9200\n",
      "Epoch 15/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5654 - acc: 0.9200\n",
      "Epoch 16/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5473 - acc: 0.9600\n",
      "Epoch 17/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5332 - acc: 0.8267\n",
      "Epoch 18/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5179 - acc: 0.9733\n",
      "Epoch 19/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5042 - acc: 0.9200\n",
      "Epoch 20/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4956 - acc: 0.9733\n",
      "Epoch 21/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4837 - acc: 0.9733\n",
      "Epoch 22/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4714 - acc: 0.9733\n",
      "Epoch 23/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4565 - acc: 0.9600\n",
      "Epoch 24/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4504 - acc: 0.9600\n",
      "Epoch 25/25\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4379 - acc: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c6fc3359b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a neural network.\n",
    "nModel = kr.models.Sequential()\n",
    "\n",
    "\n",
    "# Add an initial layer with 4 input nodes and a hidden layer with 16 nodes\n",
    "nModel.add(kr.layers.Dense(16, input_shape=(4,)))\n",
    "# Activate the sigmoid function\n",
    "nModel.add(kr.layers.Activation(\"sigmoid\"))\n",
    "\n",
    "# Add another layer\n",
    "nModel.add(kr.layers.Dense(3))\n",
    "# Activate the softmax function\n",
    "nModel.add(kr.layers.Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "# Before training a model,we need to configure the learning process, which is done via the compile method. \n",
    "#It receives three arguments:\n",
    "# 1. An optimizer which is string identifier of an existing optimizer\n",
    "# 2. A loss function. This is the objective that the model will try to minimize. \n",
    "# It is a the string identifier of an existing loss function \"categorical_crossentropy\"\n",
    "# 3.A list of metrics. For any classification problem we want to set this to metrics=['accuracy'].\n",
    "nModel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "nModel.fit(input_train, output_train, epochs=25, batch_size=1, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 80us/step\n",
      "\n",
      "\n",
      "Loss:     0.4212\tAccuracy:     0.9600\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data set.\n",
    "#evaluate() returns the list of metrics that the model was compiled with. \n",
    "loss, accuracy = nModel.evaluate(input_test, output_test, verbose=1)\n",
    "\n",
    "#Print Loss & Accuracy\n",
    "print(\"\\n\\nLoss: %10.4f\\tAccuracy: %10.4f\" % (loss, accuracy))\n",
    "\n",
    "# Save the model to a file\n",
    "m.save(\"iris_nn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
